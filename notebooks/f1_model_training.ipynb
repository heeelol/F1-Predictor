{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is dedicated to developing a robust machine learning model capable of accurately predicting Formula 1 race ranks, providing valuable insights for F1 enthusiasts and strategic analysis.\n",
    "\n",
    "Building upon the comprehensive data exploration and feature engineering from `f1_data_exploration.ipynb`, we consolidate relevant race and qualifying data into a unified pandas DataFrame. This dataset is then meticulously cleaned and prepared, leveraging a diverse set of features encompassing driver and constructor historical performance, qualifying results, circuit characteristics, and more, to capture the complex dynamics of F1 racing.\n",
    "\n",
    "The core of this notebook focuses on identifying the most suitable machine learning model and its respective hyperparameters. We will systematically explore `RandomForestRegressor` and `GradientBoostingRegressor` using advanced cross-validation and hyperparameter tuning techniques from `sklearn.model_selection`. The optimization process will prioritize not just the accuracy of predicted F1 race results, but also the efficiency and generalization of the training procedure. Model performance will be rigorously evaluated using metrics such as Mean Absolute Error (MAE) and R-squared, with a particular focus on how well the model predicts the actual finishing order.\n",
    "\n",
    "Finally, the best-performing model, along with its optimized parameters, will be serialized and saved as `f1_rank_predictor.pkl` in the `models/` directory, ready for seamless integration into the backend prediction service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import fastf1\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Race Data\n",
    "\n",
    "Race data for years 2015 to 2025 are loaded into `notebooks\\data_cache`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache directory already exists: ./data_cache\n",
      "FastF1 caching enabled to './data_cache'\n",
      "\n",
      "FastF1 log level set to ERROR to suppress verbose messages during data loading.\n",
      "\n",
      "--- Starting data collection for seasons 2015 to 2025 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 50\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m round_num \u001b[38;5;129;01min\u001b[39;00m race_events[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRoundNumber\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Pause before attempting to load each round's data\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Pause before race session\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     race_loaded_for_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     quali_loaded_for_round \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time # Import the time module\n",
    "\n",
    "# --- 1. Configure FastF1 Caching ---\n",
    "cache_dir = './data_cache'\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "    print(f\"Created cache directory: {cache_dir}\")\n",
    "else:\n",
    "    print(f\"Cache directory already exists: {cache_dir}\")\n",
    "\n",
    "fastf1.Cache.enable_cache(cache_dir)\n",
    "print(f\"FastF1 caching enabled to '{cache_dir}'\")\n",
    "\n",
    "# Suppress FastF1's default INFO messages for cleaner output during data loading\n",
    "# You can comment this line out temporarily if you want to see FastF1's internal progress.\n",
    "fastf1.set_log_level('ERROR')\n",
    "print(\"\\nFastF1 log level set to ERROR to suppress verbose messages during data loading.\")\n",
    "\n",
    "\n",
    "# --- 2. Define the Years You Want to Read ---\n",
    "start_year = 2015\n",
    "end_year = 2025 # Adjusted to prevent issues with incomplete/future season data\n",
    "\n",
    "# Lists to hold DataFrames from each race\n",
    "all_race_results = []\n",
    "all_qualifying_results = []\n",
    "\n",
    "# Dictionaries to track loading status and errors\n",
    "year_loading_status = {}\n",
    "\n",
    "print(f\"\\n--- Starting data collection for seasons {start_year} to {end_year} ---\")\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    year_loading_status[year] = {'status': 'Pending', 'races_loaded': 0, 'qual_loaded': 0, 'errors': []}\n",
    "    \n",
    "    try:\n",
    "        # Give a small pause before fetching schedule for a new year\n",
    "        time.sleep(1) \n",
    "        schedule = fastf1.get_event_schedule(year)\n",
    "        \n",
    "        race_events = schedule.loc[schedule['EventFormat'].isin(['conventional', 'sprint'])]\n",
    "        \n",
    "        if race_events.empty:\n",
    "            year_loading_status[year]['status'] = 'No Race Events'\n",
    "            year_loading_status[year]['errors'].append(f\"No 'conventional' or 'sprint' race events found for {year}. Skipping season.\")\n",
    "            continue\n",
    "\n",
    "        for round_num in race_events['RoundNumber']:\n",
    "            # Pause before attempting to load each round's data\n",
    "            time.sleep(1) # Pause before race session\n",
    "            \n",
    "            race_loaded_for_round = False\n",
    "            quali_loaded_for_round = False\n",
    "\n",
    "            try:\n",
    "                # --- Load Race Session Results ---\n",
    "                race_session = fastf1.get_session(year, round_num, 'R')\n",
    "                race_session.load(telemetry=False, laps=False, weather=False)\n",
    "\n",
    "                if race_session.results.empty:\n",
    "                    year_loading_status[year]['errors'].append(f\"WARNING: No results for Race {year} R{round_num}. Data unavailable.\")\n",
    "                else:\n",
    "                    results_df = race_session.results.copy()\n",
    "                    results_df['Season'] = year\n",
    "                    results_df['Round'] = round_num\n",
    "                    results_df['EventName'] = race_session.event['EventName']\n",
    "                    results_df['SessionType'] = 'Race'\n",
    "                    all_race_results.append(results_df)\n",
    "                    year_loading_status[year]['races_loaded'] += 1\n",
    "                    race_loaded_for_round = True\n",
    "\n",
    "                # Small pause between race and qualifying session loads for the same round\n",
    "                time.sleep(0.5)\n",
    "\n",
    "                # --- Optionally, load Qualifying Session Results ---\n",
    "                try:\n",
    "                    quali_session = fastf1.get_session(year, round_num, 'Q')\n",
    "                    quali_session.load(telemetry=False, laps=False, weather=False)\n",
    "\n",
    "                    if quali_session.results.empty:\n",
    "                        year_loading_status[year]['errors'].append(f\"WARNING: No results for Qualifying {year} R{round_num}. Data unavailable.\")\n",
    "                    else:\n",
    "                        quali_results_df = quali_session.results.copy()\n",
    "                        quali_results_df['Season'] = year\n",
    "                        quali_results_df['Round'] = round_num\n",
    "                        quali_results_df['EventName'] = quali_session.event['EventName']\n",
    "                        quali_results_df['SessionType'] = 'Qualifying'\n",
    "                        all_qualifying_results.append(quali_results_df)\n",
    "                        year_loading_status[year]['qual_loaded'] += 1\n",
    "                        quali_loaded_for_round = True\n",
    "\n",
    "                except Exception as e:\n",
    "                    year_loading_status[year]['errors'].append(f\"Error loading Qualifying for {year} R{round_num}: {e}.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                year_loading_status[year]['errors'].append(f\"CRITICAL ERROR loading session {year} R{round_num}: {e}.\")\n",
    "        \n",
    "        # Determine overall status for the year\n",
    "        if not year_loading_status[year]['errors']:\n",
    "            year_loading_status[year]['status'] = 'SUCCESS'\n",
    "        elif year_loading_status[year]['races_loaded'] > 0 or year_loading_status[year]['qual_loaded'] > 0:\n",
    "            year_loading_status[year]['status'] = 'PARTIAL SUCCESS (with errors)'\n",
    "        else:\n",
    "            year_loading_status[year]['status'] = 'FAILED'\n",
    "\n",
    "    except Exception as e:\n",
    "        year_loading_status[year]['status'] = 'SCHEDULE ERROR'\n",
    "        year_loading_status[year]['errors'].append(f\"Error retrieving schedule for {year}: {e}.\")\n",
    "\n",
    "# --- Print Summary of Data Loading ---\n",
    "print(\"\\n--- Data Loading Summary by Year ---\")\n",
    "for year, status_info in year_loading_status.items():\n",
    "    print(f\"Season {year}: {status_info['status']}\")\n",
    "    if status_info['races_loaded'] > 0:\n",
    "        print(f\"  Races Loaded: {status_info['races_loaded']}\")\n",
    "    if status_info['qual_loaded'] > 0:\n",
    "        print(f\"  Qualifying Sessions Loaded: {status_info['qual_loaded']}\")\n",
    "    if status_info['errors']:\n",
    "        print(f\"  Issues Encountered ({len(status_info['errors'])}):\")\n",
    "        for error_msg in status_info['errors']:\n",
    "            print(f\"    - {error_msg}\")\n",
    "    print(\"-\" * 30) # Separator\n",
    "\n",
    "# --- 3. Concatenate All DataFrames ---\n",
    "print(\"\\n--- Concatenating collected data ---\")\n",
    "if all_race_results:\n",
    "    full_race_results_df = pd.concat(all_race_results, ignore_index=True)\n",
    "    print(f\"Successfully collected {len(full_race_results_df)} race results entries.\")\n",
    "else:\n",
    "    print(\"No race results data collected into a DataFrame.\")\n",
    "\n",
    "if all_qualifying_results:\n",
    "    full_quali_results_df = pd.concat(all_qualifying_results, ignore_index=True)\n",
    "    print(f\"Successfully collected {len(full_quali_results_df)} qualifying results entries.\")\n",
    "else:\n",
    "    print(\"No qualifying results data collected into a DataFrame.\")\n",
    "\n",
    "print(\"\\n--- Data collection process finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We now handle any missing values in the dataframe, ensuring appropriate format for training.\n",
    "The code cell below reveals the columns in `full_race_results_df`, from which we will remove the ones unnecessary in the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DriverNumber', 'BroadcastName', 'Abbreviation', 'DriverId', 'TeamName',\n",
       "       'TeamColor', 'TeamId', 'FirstName', 'LastName', 'FullName',\n",
       "       'HeadshotUrl', 'CountryCode', 'Position', 'ClassifiedPosition',\n",
       "       'GridPosition', 'Q1', 'Q2', 'Q3', 'Time', 'Status', 'Points', 'Laps',\n",
       "       'Season', 'Round', 'EventName', 'SessionType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_race_results_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns `'DriverNumber', 'BroadcastName', 'DriverId', 'TeamColor', 'TeamId', 'FirstName', 'LastName', 'FullName', 'HeadshotUrl', 'CountryCode', 'ClassifiedPosition', 'Q1', 'Q2', 'Q3', 'Time', 'Status', 'Points', 'Laps', 'SessionType'` are dropped from the original DataFrame, and the resulting DataFrame is stored in `new_df`.\n",
    "\n",
    "As the model will be made to predict the raw `Position` of each driver, `ClassifiedPosition` is removed since race retirement is extremely situational and `Position` will instead be used as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_data_for_merge = full_race_results_df.drop(['DriverNumber', 'BroadcastName', 'DriverId', 'TeamColor', 'TeamId', 'FirstName', 'LastName', 'FullName', 'HeadshotUrl', 'CountryCode', 'ClassifiedPosition', 'Q1', 'Q2', 'Q3', 'Time', 'Status', 'Points', 'Laps', 'SessionType'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'Q1', 'Q2', and 'Q3'` are `timedelta` objects and are converted into seconds and stored respectively in the new columns `'Q1_s', 'Q2_s', and 'Q3_s'`. This will allow for its meaningful use when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new columns to hold values of 'Q1', 'Q2, and 'Q3' in seconds.\n",
    "full_quali_results_df['Q1_s'] = full_quali_results_df['Q1'].dt.total_seconds().fillna(9999.0)\n",
    "full_quali_results_df['Q2_s'] = full_quali_results_df['Q2'].dt.total_seconds().fillna(9999.0)\n",
    "full_quali_results_df['Q3_s'] = full_quali_results_df['Q3'].dt.total_seconds().fillna(9999.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since certain qualifying data are useful for training the model, we merge a subset of the 2 dataframes `full_race_results_df` and `full_quali_results_df`, keeping only the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "quali_data_for_merge = full_quali_results_df[['Abbreviation', 'Season', 'Round', 'EventName', 'Q1_s', 'Q2_s', 'Q3_s']].copy() \n",
    "\n",
    "merged_df = pd.merge(\n",
    "    race_data_for_merge,\n",
    "    quali_data_for_merge,\n",
    "    on=['Abbreviation', 'Season', 'Round', 'EventName'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Organising columns for readability and easier management\n",
    "merged_df = merged_df[[    \n",
    "    'Season',         \n",
    "    'Round',\n",
    "    'EventName',\n",
    "    'Abbreviation',   # Driver identifier eg. 'VER', 'PER', 'ALO'\n",
    "    'TeamName',      \n",
    "    'GridPosition',   # Qualifying positions, also positions in which they start on during race\n",
    "    'Q1_s',           # Q1 time in seconds\n",
    "    'Q2_s',\n",
    "    'Q3_s',\n",
    "    'Position'        # The target variable for race prediction\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Round</th>\n",
       "      <th>EventName</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>GridPosition</th>\n",
       "      <th>Q1_s</th>\n",
       "      <th>Q2_s</th>\n",
       "      <th>Q3_s</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.586</td>\n",
       "      <td>86.894</td>\n",
       "      <td>86.327</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>ROS</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.906</td>\n",
       "      <td>87.097</td>\n",
       "      <td>86.921</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>VET</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>4.0</td>\n",
       "      <td>89.307</td>\n",
       "      <td>87.742</td>\n",
       "      <td>87.757</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>MAS</td>\n",
       "      <td>Williams</td>\n",
       "      <td>3.0</td>\n",
       "      <td>89.246</td>\n",
       "      <td>87.895</td>\n",
       "      <td>87.718</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>NAS</td>\n",
       "      <td>Sauber</td>\n",
       "      <td>10.0</td>\n",
       "      <td>90.430</td>\n",
       "      <td>88.800</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>RIC</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>6.0</td>\n",
       "      <td>89.788</td>\n",
       "      <td>88.679</td>\n",
       "      <td>88.329</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>HUL</td>\n",
       "      <td>Force India</td>\n",
       "      <td>13.0</td>\n",
       "      <td>89.651</td>\n",
       "      <td>89.208</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>ERI</td>\n",
       "      <td>Sauber</td>\n",
       "      <td>15.0</td>\n",
       "      <td>91.376</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>SAI</td>\n",
       "      <td>Toro Rosso</td>\n",
       "      <td>7.0</td>\n",
       "      <td>89.597</td>\n",
       "      <td>88.601</td>\n",
       "      <td>88.510</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>PER</td>\n",
       "      <td>Force India</td>\n",
       "      <td>14.0</td>\n",
       "      <td>89.990</td>\n",
       "      <td>89.209</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>BUT</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>16.0</td>\n",
       "      <td>91.422</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>RAI</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>5.0</td>\n",
       "      <td>89.754</td>\n",
       "      <td>87.807</td>\n",
       "      <td>87.790</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>VER</td>\n",
       "      <td>Toro Rosso</td>\n",
       "      <td>11.0</td>\n",
       "      <td>89.248</td>\n",
       "      <td>88.868</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>GRO</td>\n",
       "      <td>Lotus F1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>89.537</td>\n",
       "      <td>88.589</td>\n",
       "      <td>88.560</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>MAL</td>\n",
       "      <td>Lotus F1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>89.847</td>\n",
       "      <td>88.726</td>\n",
       "      <td>89.480</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>KVY</td>\n",
       "      <td>Red Bull</td>\n",
       "      <td>12.0</td>\n",
       "      <td>90.402</td>\n",
       "      <td>89.070</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>MAG</td>\n",
       "      <td>McLaren</td>\n",
       "      <td>17.0</td>\n",
       "      <td>92.037</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>9999.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>BOT</td>\n",
       "      <td>Williams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.641</td>\n",
       "      <td>87.796</td>\n",
       "      <td>88.087</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Malaysian Grand Prix</td>\n",
       "      <td>VET</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.814</td>\n",
       "      <td>99.632</td>\n",
       "      <td>109.908</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>Malaysian Grand Prix</td>\n",
       "      <td>HAM</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.269</td>\n",
       "      <td>101.517</td>\n",
       "      <td>109.834</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season  Round              EventName Abbreviation     TeamName  \\\n",
       "0     2015      1  Australian Grand Prix          HAM     Mercedes   \n",
       "1     2015      1  Australian Grand Prix          ROS     Mercedes   \n",
       "2     2015      1  Australian Grand Prix          VET      Ferrari   \n",
       "3     2015      1  Australian Grand Prix          MAS     Williams   \n",
       "4     2015      1  Australian Grand Prix          NAS       Sauber   \n",
       "5     2015      1  Australian Grand Prix          RIC     Red Bull   \n",
       "6     2015      1  Australian Grand Prix          HUL  Force India   \n",
       "7     2015      1  Australian Grand Prix          ERI       Sauber   \n",
       "8     2015      1  Australian Grand Prix          SAI   Toro Rosso   \n",
       "9     2015      1  Australian Grand Prix          PER  Force India   \n",
       "10    2015      1  Australian Grand Prix          BUT      McLaren   \n",
       "11    2015      1  Australian Grand Prix          RAI      Ferrari   \n",
       "12    2015      1  Australian Grand Prix          VER   Toro Rosso   \n",
       "13    2015      1  Australian Grand Prix          GRO     Lotus F1   \n",
       "14    2015      1  Australian Grand Prix          MAL     Lotus F1   \n",
       "15    2015      1  Australian Grand Prix          KVY     Red Bull   \n",
       "16    2015      1  Australian Grand Prix          MAG      McLaren   \n",
       "17    2015      1  Australian Grand Prix          BOT     Williams   \n",
       "18    2015      2   Malaysian Grand Prix          VET      Ferrari   \n",
       "19    2015      2   Malaysian Grand Prix          HAM     Mercedes   \n",
       "\n",
       "    GridPosition    Q1_s      Q2_s      Q3_s  Position  \n",
       "0            1.0  88.586    86.894    86.327       1.0  \n",
       "1            2.0  88.906    87.097    86.921       2.0  \n",
       "2            4.0  89.307    87.742    87.757       3.0  \n",
       "3            3.0  89.246    87.895    87.718       4.0  \n",
       "4           10.0  90.430    88.800  9999.000       5.0  \n",
       "5            6.0  89.788    88.679    88.329       6.0  \n",
       "6           13.0  89.651    89.208  9999.000       7.0  \n",
       "7           15.0  91.376  9999.000  9999.000       8.0  \n",
       "8            7.0  89.597    88.601    88.510       9.0  \n",
       "9           14.0  89.990    89.209  9999.000      10.0  \n",
       "10          16.0  91.422  9999.000  9999.000      11.0  \n",
       "11           5.0  89.754    87.807    87.790      12.0  \n",
       "12          11.0  89.248    88.868  9999.000      13.0  \n",
       "13           8.0  89.537    88.589    88.560      14.0  \n",
       "14           9.0  89.847    88.726    89.480      15.0  \n",
       "15          12.0  90.402    89.070  9999.000      16.0  \n",
       "16          17.0  92.037  9999.000  9999.000      17.0  \n",
       "17           0.0  89.641    87.796    88.087      18.0  \n",
       "18           2.0  99.814    99.632   109.908       1.0  \n",
       "19           1.0  99.269   101.517   109.834       2.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quali_data_for_merge = full_quali_results_df[['Abbreviation', 'Season', 'Round', 'EventName', 'Q1_s', 'Q2_s', 'Q3_s']].copy()\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    race_data_for_merge,\n",
    "    quali_data_for_merge,\n",
    "    on=['Abbreviation', 'Season', 'Round', 'EventName'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Organising columns for readability and easier management\n",
    "merged_df = merged_df[[\n",
    "    'Season', \n",
    "    'Round',\n",
    "    'EventName',\n",
    "    'Abbreviation', # Driver identifier eg. 'VER', 'PER', 'ALO'\n",
    "    'TeamName',\n",
    "    'GridPosition', # Qualifying positions, also positions in which they start on during race\n",
    "    'Q1_s', # Q1 time in seconds\n",
    "    'Q2_s',\n",
    "    'Q3_s',\n",
    "    'Position' # The target variable for race prediction\n",
    "]]\n",
    "\n",
    "merged_df.head(20) # DataFrame snippet of race 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the 2023 Singapore Grand Prix, driver Lance Stroll was withdrawn from the Sunday race following a heavy crash during Saturday's qualifying session. \n",
    "\n",
    "As a result, we see an empty value for Stroll's `'GridPosition'` and `'Position'`for the event.\n",
    "\n",
    "As there are instances (rows 197, 241, 278, 633) where drivers starting from the pitlanes has resulted in `'GridPosition'` and `'Position'` holding the value of 0.0, we deduce that this is an anomaly on the side of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result should be 1, referring to this singular anomaly\n",
    "print(\"Number of rows with missing values for 'GridPosition' before cleaning:\", merged_df['GridPosition'].isna().sum())\n",
    "\n",
    "# A simple fix would be to replace all missing values with 0.0\n",
    "merged_df.loc[merged_df['GridPosition'].isna(), 'GridPosition'] = 0.0\n",
    "merged_df.loc[merged_df['Position'].isna(), 'Position'] = 0.0\n",
    "merged_df.loc[merged_df['Q1_s'].isna(), 'Q1_s'] = 0.0\n",
    "merged_df.loc[merged_df['Q2_s'].isna(), 'Q2_s'] = 0.0\n",
    "merged_df.loc[merged_df['Q3_s'].isna(), 'Q3_s'] = 0.0\n",
    "\n",
    "# Result after cleaning\n",
    "print(\"Number of rows with missing values for 'GridPosition' after cleaning:\", merged_df['GridPosition'].isna().sum())\n",
    "\n",
    "#merged_df.to_csv(os.path.join(os.getcwd(), 'merged_df.csv'), index=False) # This optional line creates a .csv file for better visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot Encoding\n",
    "\n",
    "Now that we have the prepared `merged_df`, we have to convert categorical (non-numerical) data into a numerical format that machine learning algorithms can understand and process effectively. \n",
    "\n",
    "Let us look at the `'TeamName'` column. Without one-hot encoding, if we were to simply assign each team values eg. Red Bull = 1, Ferrari = 2, Mercedes = 3, a machine learning model would interpret these numbers as having an inherent order or magnitude. It might think that Mercedes (3) is \"better\" or \"more important\" or \"further away\" from Red Bull (1) than Ferrari (2) is. This is clearly false for nominal categories like team names, where there's no inherent numerical relationship. This false ordinality can mislead the model and lead to incorrect predictions or reduced performance.\n",
    "\n",
    "With one-hot encoding, we create new binary (0 or 1) columns for every team that exists. If in row 1 was Max Verstappen from team Red bull Racing, we would now have a value of 1 in Team_RedBull and a 0 in the columns of every other team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define categorical columns for one-hot encoding\n",
    "categorical_cols_to_encode = ['Abbreviation', 'TeamName', 'EventName']\n",
    "\n",
    "print(f\"\\nOriginal DataFrame shape: {merged_df.shape}\")\n",
    "\n",
    "# --- Initialize and Fit One-Hot Encoder ---\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the categorical columns of your training data\n",
    "ohe.fit(merged_df[categorical_cols_to_encode])\n",
    "\n",
    "# --- Transform the DataFrame ---\n",
    "# Apply the fitted encoder to transform the categorical columns\n",
    "encoded_features = ohe.transform(merged_df[categorical_cols_to_encode])\n",
    "\n",
    "# Create a DataFrame from the encoded features with proper column names\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_features.astype(int), \n",
    "    columns=ohe.get_feature_names_out(categorical_cols_to_encode),\n",
    "    index=merged_df.index\n",
    ")\n",
    "\n",
    "# Drop the original categorical columns from merged_df\n",
    "numerical_and_other_features_df = merged_df.drop(columns=categorical_cols_to_encode)\n",
    "\n",
    "# Concatenate the original numerical/other features with the new encoded features\n",
    "merged_df_encoded = pd.concat([numerical_and_other_features_df, encoded_df], axis=1)\n",
    "\n",
    "# Note the increase in number of columns after encoding\n",
    "print(f\"Encoded DataFrame shape: {merged_df_encoded.shape}\")\n",
    "\n",
    "\n",
    "# --- IMPORTANT: Save the fitted OneHotEncoder ---\n",
    "# This is crucial for preprocessing.py to work correctly for new data.\n",
    "models_dir = os.path.join('..', 'models')\n",
    "os.makedirs(models_dir, exist_ok=True) # Ensure the 'models' directory exists\n",
    "\n",
    "joblib.dump(ohe, os.path.join(models_dir, 'one_hot_encoder.joblib'))\n",
    "print(f\"Fitted OneHotEncoder saved successfully to: {os.path.join(models_dir, 'one_hot_encoder.joblib')}\")\n",
    "\n",
    "# You will also need to save your scaler and the final training feature names, as discussed previously.\n",
    "joblib.dump(merged_df_encoded.columns.tolist(), os.path.join(models_dir, 'training_feature_names.joblib'))\n",
    "\n",
    "#merged_df_encoded.to_csv(os.path.join(os.getcwd(), 'merged_df_encoded.csv'), index=False) # This optional line creates a .csv file for better visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "Splitting data into features (X) and the target variable (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "y = merged_df_encoded['Position']\n",
    "\n",
    "# Define the features (X) by dropping the target and any other non-feature columns\n",
    "columns_to_exclude_from_X = ['Position'] # Only exclude the target variable\n",
    "\n",
    "X = merged_df_encoded.drop(columns=columns_to_exclude_from_X, axis=1)\n",
    "\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data with 80% for training and 20% for testing\n",
    "# random_state ensures reproducibility of your split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTrain set shape (X_train, y_train): {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test set shape (X_test, y_test): {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose __Candidate Models__ and define __Hyperparameter Grids__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "# Define the scoring metric for optimization\n",
    "# For MAE, lower is better, so we use 'neg_mean_absolute_error' for GridSearchCV\n",
    "# which maximizes the score.\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# --- Model 1: RandomForestRegressor ---\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': [0.6, 0.8, 1.0],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# --- Model 2: GradientBoostingRegressor ---\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 700],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "}\n",
    "\n",
    "# You could add more models here, e.g.,\n",
    "# from xgboost import XGBRegressor\n",
    "# xgb_model = XGBRegressor(random_state=42)\n",
    "# xgb_param_grid = { ... }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform __Hyperparameter Tuning__ with Cross-Validation (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GridSearchCV for RandomForestRegressor ---\n",
    "print(\"\\n--- Starting GridSearchCV for RandomForestRegressor ---\")\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=rf_param_grid,\n",
    "    scoring=mae_scorer,\n",
    "    cv=5,            # 5-fold cross-validation\n",
    "    n_jobs=-1,       # Use all available CPU cores\n",
    "    verbose=1        # Show progress\n",
    ")\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters for RandomForestRegressor:\", rf_grid_search.best_params_)\n",
    "print(\"Best cross-validated MAE for RandomForestRegressor:\", -rf_grid_search.best_score_)\n",
    "\n",
    "\n",
    "# --- GridSearchCV for GradientBoostingRegressor ---\n",
    "print(\"\\n--- Starting GridSearchCV for GradientBoostingRegressor ---\")\n",
    "gb_grid_search = GridSearchCV(\n",
    "    estimator=gb_model,\n",
    "    param_grid=gb_param_grid,\n",
    "    scoring=mae_scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters for GradientBoostingRegressor:\", gb_grid_search.best_params_)\n",
    "print(\"Best cross-validated MAE for GradientBoostingRegressor:\", -gb_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluate the Best Models on the Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "print(\"--- Step 5: Evaluate the Best Models on the Test Set ---\")\n",
    "\n",
    "# Retrieve the best models from GridSearchCV\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "best_gb_model = gb_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = best_rf_model.predict(X_test)\n",
    "gb_predictions = best_gb_model.predict(X_test)\n",
    "\n",
    "print(\"\\n--- RandomForestRegressor Evaluation ---\")\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "\n",
    "print(f\"RandomForestRegressor MAE on Test Set: {rf_mae:.4f}\")\n",
    "print(f\"RandomForestRegressor R2 on Test Set: {rf_r2:.4f}\")\n",
    "print(f\"RandomForestRegressor RMSE on Test Set: {rf_rmse:.4f}\")\n",
    "\n",
    "print(\"\\n--- GradientBoostingRegressor Evaluation ---\")\n",
    "gb_mae = mean_absolute_error(y_test, gb_predictions)\n",
    "gb_r2 = r2_score(y_test, gb_predictions)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, gb_predictions))\n",
    "\n",
    "print(f\"GradientBoostingRegressor MAE on Test Set: {gb_mae:.4f}\")\n",
    "print(f\"GradientBoostingRegressor R2 on Test Set: {gb_r2:.4f}\")\n",
    "print(f\"GradientBoostingRegressor RMSE on Test Set: {gb_rmse:.4f}\")\n",
    "\n",
    "# You can also compare them:\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "if rf_mae < gb_mae:\n",
    "    print(\"RandomForestRegressor performed better in terms of MAE.\")\n",
    "elif gb_mae < rf_mae:\n",
    "    print(\"GradientBoostingRegressor performed better in terms of MAE.\")\n",
    "else:\n",
    "    print(\"Both models have similar MAE.\")\n",
    "\n",
    "# Optional: Store evaluation metrics for later analysis if needed\n",
    "evaluation_results = {\n",
    "    'RandomForestRegressor': {'MAE': rf_mae, 'R2': rf_r2, 'RMSE': rf_rmse},\n",
    "    'GradientBoostingRegressor': {'MAE': gb_mae, 'R2': gb_r2, 'RMSE': gb_rmse}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the Final Model and Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "print(\"--- Model Selection ---\")\n",
    "\n",
    "# Based on evaluation results, GradientBoostingRegressor is the chosen model.\n",
    "# Assuming gb_grid_search is defined and available from previous cells in the notebook\n",
    "best_model_to_save = gb_grid_search.best_estimator_ # Access the best estimator from GridSearchCV\n",
    "model_name = \"GradientBoosting\"\n",
    "\n",
    "print(f\"\\nSelected final model: {model_name}\")\n",
    "print(\"Best parameters for selected model:\")\n",
    "print(best_model_to_save.get_params())\n",
    "\n",
    "\n",
    "# Model Persistence (Saving the Model)\n",
    "# Define the relative path to the 'models' directory\n",
    "# This assumes the notebook is run from within the 'notebooks' directory\n",
    "# and 'models' is a sibling directory to 'notebooks'\n",
    "model_dir = os.path.join('..', 'models')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Construct the full path for the model file\n",
    "model_filename = os.path.join(model_dir, f'{model_name}_F1_Race_Predictor_model.joblib')\n",
    "\n",
    "joblib.dump(best_model_to_save, model_filename, compress=3)\n",
    "\n",
    "print(f\"\\nModel saved successfully to: {model_filename}\")\n",
    "\n",
    "# Loading the Model to Verify\n",
    "print(\"\\n--- Verifying Model Loading (Optional) ---\")\n",
    "loaded_model = joblib.load(model_filename)\n",
    "print(f\"Model loaded successfully: {loaded_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
